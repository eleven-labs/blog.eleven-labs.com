---
contentType: article
lang: fr
date: 2025-01-08
slug: environnement-gitlab-ci
title: Cr√©er un environnement de revue avec Gitlab CI
excerpt: Apr√®s avoir d√©velopp√© une nouvelle fonctionnalit√© pour votre application, le code est revue par l'√©quipe. Pour que le relecteur puisse mieux se rendre compte des changements, il est int√©ressant de mettre les changements √† disposition dans un environnement de revue. Cet article va expliquer les √©tapes pour le faire avec Gitlab CI.
cover:
    alt: Comment cr√©er un environnement de revue avec Gitlab CI ?
    path: /imgs/articles/2025-01-08-gitlab-review-environment/cover.jpg
categories:
    - architecture
keywords:
  - devops
  - gitlab
authors:
    - tthuon
seo:
    title: "Cr√©er un environnement de revue avec Gitlab CI : m√©thode"
    description: D√©couvrez comment cr√©er une environnement de revue dynamique avec Gitlab CI.
---

Dans une √©quipe de d√©veloppement, une des bonnes pratiques consiste √† relire le code des autres membres de l'√©quipe. Cela permet de partager la connaissance et d'avoir un oeil diff√©rent sur le code produit. Pour aller encore plus loin, ce code pourrait √™tre d√©ploy√© dans un environnement isol√© : un environnement de revue.

Voyons comment le mettre en oeuvre avec Gitlab CI.

## Cr√©er un environnement de revue avec Gitlab CI

Dans le contexte d'un projet data, nous avons du code Python que nous devons mettre √† disposition dans un stockage objet Google Cloud Storage. Ce code est lu et ex√©cut√© par le service Google Dataproc.

Gitlab CI a une fonctionnalit√© qui permet de cr√©er des environnements √† la vol√©e.

Prenons ce fichier `.gitlab-ci.yml` initial.

```yaml
variables:
  DATAPROC_CLUSTER_NAME: review-${CI_COMMIT_REF_SLUG}
  DATAPROC_IMAGE_VERSION: 2.2.21-debian12
  DELTA_SPARK_VERSION: 3.2.0
  GCP_PROJECT_ID: my-project

stages:
  - deploy

deploy:review:
  stage: deploy
  image: hub.docker.com/google/cloud-sdk:alpine
  before_script:
    - gcloud auth activate-service-account --key-file $GCP_SA_KEY_DEV
    - gcloud config set project ${GCP_PROJECT_ID}
  script: |
    if [ $(gcloud dataproc clusters list --region=europe-west1 --filter=clusterName:$DATAPROC_CLUSTER_NAME --format="value(clusterName)" | wc -l) -eq 0 ]; then
      gcloud dataproc clusters create ${DATAPROC_CLUSTER_NAME} --enable-component-gateway --region=europe-west1 --master-machine-type=n1-standard-4 --worker-machine-type=n1-highmem-4 --num-workers=3 --num-masters=1 --master-boot-disk-size=1000 --worker-boot-disk-size=1000 --image-version=${DATAPROC_IMAGE_VERSION} --optional-components=JUPYTER --max-idle=1h --public-ip-address --properties=^#^spark:spark.jars=gs://${GCP_PROJECT_ID}/jars/delta-spark_2.12-${DELTA_SPARK_VERSION}.jar,gs://${GCP_PROJECT_ID}/jars/delta-storage-${DELTA_SPARK_VERSION}.jar#dataproc:pip.packages=delta-spark==${DELTA_SPARK_VERSION} --labels=environment-type=review,environment-name=${CI_COMMIT_REF_SLUG}
    fi
    gsutil -m rsync -d -x ".git|venv|__pycache__" -r ./ gs://${GCP_PROJECT_ID}/${CI_COMMIT_REF_SLUG}/spark-app
  rules:
    - if: $CI_MERGE_REQUEST_IID
```

La t√¢che de d√©ploiement va v√©rifier la pr√©sence d'un cluster Dataproc. S'il n'existe pas, alors le cluster est cr√©√©. Les options ne sont pas importantes dans le cadre de l'article. Enfin, les fichiers sont copi√© dans le stockage objet avec la commande `gsutil`.

√Ä partir de cette base, ajoutons la configuration pour cr√©er un environnement dynamique. Nous voulons que cet environnement soit configur√© de cette fa√ßon :
- pr√©fix√© par `review/`
- auto d√©truit apr√®s 1 jour
- le bouton pour voir l'environnement ouvre la console Google Cloud Platform sur le cluster Dataproc

Cela se traduit par la configuration suivante qui sera √† ajouter √† notre t√¢che de `deploy:review`.

```yaml
deploy:review:
  (...)
  environment:
    deployment_tier: testing
    name: review/${CI_COMMIT_REF_SLUG}
    action: start
    auto_stop_in: 1 day
    on_stop: deploy:review:stop
    url: https://console.cloud.google.com/dataproc/clusters/${DATAPROC_CLUSTER_NAME}/monitoring?region=europe-west1&project=${GCP_PROJECT_ID}
```

La cl√© `on_stop` dans l'objet `environment` fait r√©f√©rence √† une t√¢che `deploy:review:stop`. C'est cette t√¢che qui sera ex√©cut√©e lorsque l'environnement sera d√©truit par Gitlab.

Ajoutons cette t√¢che `deploy:review:stop`.

```yaml

deploy:review:stop:
  stage: deploy
  image: hub.docker.com/google/cloud-sdk:alpine
  before_script:
    - gcloud auth activate-service-account --key-file $GCP_SA_KEY_DEV
    - gcloud config set project ${GCP_PROJECT_ID}
  script:
    - gcloud dataproc clusters delete ${DATAPROC_CLUSTER_NAME} --region=europe-west1 --quiet || true
  rules:
    - if: $CI_MERGE_REQUEST_IID
      when: manual
  environment:
    name: review/${CI_COMMIT_REF_SLUG}
    action: stop
```

La t√¢che `deploy:review:stop` a bien une configuration `environment` avec la r√©f√©rence vers le nom de l'environnement √† stopper, ainsi que l'action √† effectuer.

Dans le cas d'une merge request, un environnement dynamique est automatiquement arr√™t√© lorsque la branche est fusionn√©e dans la branche principale.

Lorsque vous allez cr√©er une nouvelle merge request, les t√¢ches de d√©ploiement en environnement de revue se lance. Quelques minutes plus tard, l'environnement est disponible.

La liste des environnements actifs est disponible dans le menu √† gauche : Operate > Environments.

## Conclusion

Bravo, vous avez cr√©√© un environnement de revue dynamique pour vos merge request. Cela va grandement faciliter la revue de code et va vous permettre de voir concr√®tement les changements. Votre Product Owner va adorer ü§© !

## R√©f√©rence

- https://docs.gitlab.com/ee/ci/environments/


Code complet

```yaml
variables:
  DATAPROC_CLUSTER_NAME: review-${CI_COMMIT_REF_SLUG}
  DATAPROC_IMAGE_VERSION: 2.2.21-debian12
  DELTA_SPARK_VERSION: 3.2.0
  GCP_PROJECT_ID: my-project

stages:
  - deploy

deploy:review:
  stage: deploy
  image: hub.docker.com/google/cloud-sdk:alpine
  before_script:
    - gcloud auth activate-service-account --key-file $GCP_SA_KEY_DEV
    - gcloud config set project ${GCP_PROJECT_ID}
  script: |
    if [ $(gcloud dataproc clusters list --region=europe-west1 --filter=clusterName:$DATAPROC_CLUSTER_NAME --format="value(clusterName)" | wc -l) -eq 0 ]; then
      gcloud dataproc clusters create ${DATAPROC_CLUSTER_NAME} --enable-component-gateway --region=europe-west1 --master-machine-type=n1-standard-4 --worker-machine-type=n1-highmem-4 --num-workers=3 --num-masters=1 --master-boot-disk-size=1000 --worker-boot-disk-size=1000 --image-version=${DATAPROC_IMAGE_VERSION} --optional-components=JUPYTER --max-idle=1h --public-ip-address --properties=^#^spark:spark.jars=gs://${GCP_PROJECT_ID}/jars/delta-spark_2.12-${DELTA_SPARK_VERSION}.jar,gs://${GCP_PROJECT_ID}/jars/delta-storage-${DELTA_SPARK_VERSION}.jar#dataproc:pip.packages=delta-spark==${DELTA_SPARK_VERSION} --labels=environment-type=review,environment-name=${CI_COMMIT_REF_SLUG}
    fi
    gsutil -m rsync -d -x ".git|venv|__pycache__" -r ./ gs://${GCP_PROJECT_ID}/${CI_COMMIT_REF_SLUG}/spark-app
  rules:
    - if: $CI_MERGE_REQUEST_IID
  environment:
    deployment_tier: testing
    name: review/${CI_COMMIT_REF_SLUG}
    action: start
    auto_stop_in: 1 day
    on_stop: deploy:review:stop
    url: https://console.cloud.google.com/dataproc/clusters/${DATAPROC_CLUSTER_NAME}/monitoring?region=europe-west1&project=${GCP_PROJECT_ID}

deploy:review:stop:
  stage: deploy
  image: hub.docker.com/google/cloud-sdk:alpine
  before_script:
    - gcloud auth activate-service-account --key-file $GCP_SA_KEY_DEV
    - gcloud config set project ${GCP_PROJECT_ID}
  script:
    - gcloud dataproc clusters delete ${DATAPROC_CLUSTER_NAME} --region=europe-west1 --quiet || true
  rules:
    - if: $CI_MERGE_REQUEST_IID
      when: manual
  environment:
    name: review/${CI_COMMIT_REF_SLUG}
    action: stop
```
